{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc942d57",
   "metadata": {},
   "source": [
    "# INR Demo\n",
    " This notebook will provide a brief demonstration of how our INR implementations can be used. In all five experiments we will fit an INR to an image from the Cifar10 dataset. The model hyperparameters are stored in separate .yaml files which are loaded in using `omegaconf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1425fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if not \"./flexconv\" in sys.path:\n",
    "    sys.path.insert(0, './flexconv')\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchviz import make_dot\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from omegaconf import OmegaConf\n",
    "import time\n",
    "\n",
    "from INR import regularize_gabornet\n",
    "from INR import MLP\n",
    "from INR import Gabor\n",
    "from INR.utils import cifar_grid, coordinate_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2003509",
   "metadata": {},
   "source": [
    "The follwing cell can be used to determine which experiments will be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7884174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_RELU_MLP_INR = False\n",
    "RUN_SINE_MLP_INR1 = False\n",
    "RUN_SINE_MLP_INR2 = False\n",
    "\n",
    "RUN_SIREN = True\n",
    "\n",
    "RUN_GABOR1 = True\n",
    "RUN_GABOR2 = True\n",
    "\n",
    "IMAGE_IDX = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c35240",
   "metadata": {},
   "source": [
    "We will be using the Cifar10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ab5ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = CIFAR10(transform=ToTensor(), root=\"data\", download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15286faf",
   "metadata": {},
   "source": [
    "The following image will be used to train all INRs on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650c2083",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_img = training_set.__getitem__(IMAGE_IDX)\n",
    "plt.imshow(training_img[0].permute((1,2,0)))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a32f8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = training_img[0].permute((1,2,0))\n",
    "\n",
    "# Used for calculating the PSNR\n",
    "MAX_I_CHANNEL = input_img.max().item()\n",
    "MAX_I = input_img.mean(2).max().item()\n",
    "\n",
    "# Load in all model hyperparameters\n",
    "cfg_ReLU = OmegaConf.load('./configs/RELU_MLP_INR_cfg.yaml')\n",
    "cfg_sine1 = OmegaConf.load('./configs/RELU_SINE_INR1_cfg.yaml')\n",
    "cfg_sine2 = OmegaConf.load('./configs/RELU_SINE_INR2_cfg.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f747ad24",
   "metadata": {},
   "source": [
    "This notebook does not use the `coordinate_grid` function, since the `cifar_grid` function works well enough for Cifar. The `coordinate_grid` function takes a list or tensor of ranges (e.g. `[[-1,1], [0,10]]`) and a list of sizes (i.e. the number of samples per dimension) and creates a coordinate grid using the cartesion product of linspaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c696ee31",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = [[0,10], [-10,10], [-10, 0]]\n",
    "size = [10, 20, 10]\n",
    "\n",
    "# A demo of the coordinate_grid function\n",
    "print(coordinate_grid(domain, size).size())\n",
    "\n",
    "# Note that setting reshape to False will collapse all domain dimensions into one\n",
    "print(coordinate_grid(domain, size, reshape=False).size())\n",
    "\n",
    "# By default the size is set to make unit steps:\n",
    "domain = [[-3,3],[0,1]]\n",
    "print(coordinate_grid(domain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4506e70d",
   "metadata": {},
   "source": [
    "Here the first few experiments are run. All models used here are MLPs (either ReLU MLPs or Sirens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229148ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We will be using the same coordinates for all models\n",
    "train_coordinates = cifar_grid(32)\n",
    "\n",
    "# Setup the first model and its optimization scheme\n",
    "relu_MLP_INR = MLP(**cfg_ReLU)\n",
    "optimizer = torch.optim.Adam(relu_MLP_INR.model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.8)\n",
    "\n",
    "# Run the first experiment\n",
    "if RUN_RELU_MLP_INR:\n",
    "    t_relu_start = time.time()\n",
    "    epochs = [1500]*5\n",
    "    relu_losses = relu_MLP_INR.fit(input_img, optimizer, criterion, scheduler, epochs, image_grid=train_coordinates)\n",
    "    t_relu_end = time.time()\n",
    "    print(\"Time ReLU:\", t_relu_end-t_relu_start)\n",
    "    plt.plot(relu_losses)\n",
    "\n",
    "    \n",
    "\n",
    "# Setup the second model and its optimization scheme\n",
    "sine_MLP1_INR = MLP(**cfg_sine1)\n",
    "optimizer = torch.optim.Adam(sine_MLP1_INR.model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.8)\n",
    "\n",
    "# Run the second experiment\n",
    "if RUN_SINE_MLP_INR1:\n",
    "    t_sine1_start = time.time()\n",
    "    epochs = [5]*200\n",
    "    sine1_losses = sine_MLP1_INR.fit(input_img, optimizer, criterion, scheduler, epochs, image_grid=train_coordinates)\n",
    "    t_sine1_end = time.time()\n",
    "    print(\"Time Sine 1:\", t_sine1_end-t_sine1_start)\n",
    "    plt.plot(sine1_losses)\n",
    "\n",
    "\n",
    "    \n",
    "# Setup the third model and its optimization scheme.\n",
    "sine_MLP2_INR = MLP(**cfg_sine2)\n",
    "optimizer = torch.optim.Adam(sine_MLP2_INR.model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.01)\n",
    "\n",
    "# Run the third experiment\n",
    "if RUN_SINE_MLP_INR2:\n",
    "    t_sine2_start = time.time()\n",
    "    epochs = [200]*5\n",
    "    sine2_losses = sine_MLP2_INR.fit(input_img, optimizer, criterion, scheduler, epochs, image_grid=train_coordinates)\n",
    "    t_sine2_end = time.time()\n",
    "    print(\"Time Sine 2:\", t_sine2_end-t_sine2_start)\n",
    "    plt.plot(sine2_losses)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25df9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the learned image representations\n",
    "\n",
    "with torch.no_grad():\n",
    "    coordinates1 = cifar_grid(32)\n",
    "    coordinates2 = cifar_grid(64)\n",
    "    coordinates3 = cifar_grid(128)\n",
    "    coordinates4 = cifar_grid(256)\n",
    "    \n",
    "    out1_relu = relu_MLP_INR(coordinates1)\n",
    "    out2_relu = relu_MLP_INR(coordinates2)\n",
    "    out3_relu = relu_MLP_INR(coordinates3)\n",
    "    out4_relu = relu_MLP_INR(coordinates4)\n",
    "    \n",
    "    out1_sine1 = sine_MLP1_INR(coordinates1)\n",
    "    out2_sine1 = sine_MLP1_INR(coordinates2)\n",
    "    out3_sine1 = sine_MLP1_INR(coordinates3)\n",
    "    out4_sine1 = sine_MLP1_INR(coordinates4)\n",
    "    \n",
    "    out1_sine2 = sine_MLP2_INR(coordinates1)\n",
    "    out2_sine2 = sine_MLP2_INR(coordinates2)\n",
    "    out3_sine2 = sine_MLP2_INR(coordinates3)\n",
    "    out4_sine2 = sine_MLP2_INR(coordinates4)\n",
    "    \n",
    "    loss_relu = criterion(out1_relu, input_img).item()\n",
    "    loss_sine1 = criterion(out1_sine1, input_img).item()\n",
    "    loss_sine2 = criterion(out1_sine2, input_img).item()\n",
    "    \n",
    "    print(\"MSE ReLU:\", loss_relu)\n",
    "    print(\"PSNR ReLU:\", 20 * np.log10(MAX_I_CHANNEL) - 10 * np.log10(loss_relu))\n",
    "    print()\n",
    "    \n",
    "    print(\"MSE sine1:\", loss_sine1)\n",
    "    print(\"PSNR sine1:\", 20 * np.log10(MAX_I_CHANNEL) - 10 * np.log10(loss_sine1))\n",
    "    print()\n",
    "    \n",
    "    print(\"MSE sine2:\", loss_sine2)\n",
    "    print(\"PSNR sine2:\", 20 * np.log10(MAX_I_CHANNEL) - 10 * np.log10(loss_sine2))\n",
    "    print()\n",
    "    \n",
    "    fig, ax = plt.subplots(3,5,figsize=(20,8))\n",
    "    \n",
    "    ax[0][0].imshow(input_img)\n",
    "    ax[0][0].axis('off')\n",
    "    ax[0][1].imshow(out1_relu)\n",
    "    ax[0][1].axis('off')\n",
    "    ax[0][2].imshow(out2_relu)\n",
    "    ax[0][2].axis('off')\n",
    "    ax[0][3].imshow(out3_relu)\n",
    "    ax[0][3].axis('off')\n",
    "    ax[0][4].imshow(out4_relu)\n",
    "    ax[0][4].axis('off')\n",
    "    \n",
    "    ax[1][0].imshow(input_img)\n",
    "    ax[1][0].axis('off')\n",
    "    ax[1][1].imshow(out1_sine1)\n",
    "    ax[1][1].axis('off')\n",
    "    ax[1][2].imshow(out2_sine1)\n",
    "    ax[1][2].axis('off')\n",
    "    ax[1][3].imshow(out3_sine1)\n",
    "    ax[1][3].axis('off')\n",
    "    ax[1][4].imshow(out4_sine1)\n",
    "    ax[1][4].axis('off')\n",
    "    \n",
    "    ax[2][0].imshow(input_img)\n",
    "    ax[2][0].axis('off')\n",
    "    ax[2][1].imshow(out1_sine2)\n",
    "    ax[2][1].axis('off')\n",
    "    ax[2][2].imshow(out2_sine2)\n",
    "    ax[2][2].axis('off')\n",
    "    ax[2][3].imshow(out3_sine2)\n",
    "    ax[2][3].axis('off')\n",
    "    ax[2][4].imshow(out4_sine2)\n",
    "    ax[2][4].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c36b345",
   "metadata": {},
   "source": [
    "The fourth experiment (below) uses a multiplicative filter network (MFN) with Gabor filters as the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd90e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These same coordinates are used as before\n",
    "train_coordinates = cifar_grid(32)\n",
    "\n",
    "# Setup the fourth model and its optimization scheme\n",
    "cfg_gabor1 = OmegaConf.load('./configs/Gabor_INR_cfg1.yaml')\n",
    "Gabor1 = Gabor(**cfg_gabor1.net)\n",
    "epochs = [300]*1\n",
    "optimizer = torch.optim.Adam(Gabor1.parameters(), lr=cfg_gabor1.train.lr)\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.9)\n",
    "\n",
    "# Run the fourth experiment\n",
    "if RUN_GABOR1:\n",
    "    t_gabor_start = time.time()\n",
    "    gabor_losses = Gabor1.fit(input_img, optimizer, criterion, scheduler, epochs, image_grid=train_coordinates)\n",
    "    t_gabor_end = time.time()\n",
    "    print(\"Time Gabor:\", t_gabor_end-t_gabor_start)\n",
    "    plt.plot(gabor_losses)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1875d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    coordinates1 = cifar_grid(32)\n",
    "    coordinates2 = cifar_grid(64)\n",
    "    coordinates3 = cifar_grid(128)\n",
    "    coordinates4 = cifar_grid(256)\n",
    "    \n",
    "    out1_gabor = Gabor1(coordinates1)\n",
    "    out2_gabor = Gabor1(coordinates2)\n",
    "    out3_gabor = Gabor1(coordinates3)\n",
    "    out4_gabor = Gabor1(coordinates4)\n",
    "    \n",
    "    loss_gabor1 = criterion(out1_gabor, input_img).item()\n",
    "    \n",
    "    print(\"MSE gabor:\", loss_gabor1)\n",
    "    print(\"PSNR sine2:\", 20 * np.log10(MAX_I_CHANNEL) - 10 * np.log10(loss_gabor1))\n",
    "    \n",
    "    fig, ax = plt.subplots(1,5,figsize=(20,8))\n",
    "    \n",
    "    ax[0].imshow(input_img)\n",
    "    ax[0].axis('off')\n",
    "    ax[1].imshow(out1_gabor.reshape((32, 32, 3)))\n",
    "    ax[1].axis('off')\n",
    "    ax[2].imshow(out2_gabor.reshape((64, 64, 3)))\n",
    "    ax[2].axis('off')\n",
    "    ax[3].imshow(out3_gabor.reshape((128, 128, 3)))\n",
    "    ax[3].axis('off')\n",
    "    ax[4].imshow(out4_gabor.reshape((256, 256, 3)))\n",
    "    ax[4].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c345fe7",
   "metadata": {},
   "source": [
    "The cell below visualizes the backwards graph of a Gabornet with regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72fc5f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize the graph\n",
    "Gabor_visualize = Gabor(**cfg_gabor1.net)\n",
    "Gabor_visualize.train()\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "out = Gabor_visualize(coordinates1)\n",
    "loss = criterion(out, input_img)\n",
    "gabor_reg = regularize_gabornet(gabor_net=Gabor_visualize.model, **cfg_gabor1.regularize_params)\n",
    "make_dot(loss + gabor_reg, params=dict(Gabor_visualize.named_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223a6eff",
   "metadata": {},
   "source": [
    "In the cell below the fifth and final experiment is run. This experiment again uses an MFN with Gabor filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5646e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setup the fourth model and its optimization scheme\n",
    "cfg_gabor2 = OmegaConf.load('./configs/Gabor_INR_cfg2.yaml')\n",
    "Gabor2 = Gabor(**cfg_gabor2.net)\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "params = set(Gabor2.model.parameters())\n",
    "for gabor_filter in Gabor2.model.filters:\n",
    "    params.union(set(gabor_filter.parameters()))\n",
    "optimizer = torch.optim.Adam(params, lr=cfg_gabor2.train.lr)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.7)\n",
    "epochs = [100]*10\n",
    "\n",
    "# Run the fourth experiment\n",
    "if RUN_GABOR2:\n",
    "    Gabor2.fit(input_img, optimizer, criterion, scheduler, epochs, image_grid=train_coordinates, regularize=True,\n",
    "               **cfg_gabor2.regularize_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dac2fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out1_gabor = Gabor2(coordinates1)\n",
    "    out2_gabor = Gabor2(coordinates2)\n",
    "    out3_gabor = Gabor2(coordinates3)\n",
    "    out4_gabor = Gabor2(coordinates4)\n",
    "    \n",
    "    loss_gabor2 = criterion(out1_gabor, input_img).item()\n",
    "    \n",
    "    print(\"MSE gabor2:\", loss_gabor2)\n",
    "    print(\"PSNR sine2:\", 20 * np.log10(MAX_I_CHANNEL) - 10 * np.log10(loss_gabor2))\n",
    "    \n",
    "    fig, ax = plt.subplots(1,5,figsize=(20,8))\n",
    "    \n",
    "    ax[0].imshow(input_img)\n",
    "    ax[0].axis('off')\n",
    "    ax[1].imshow(out1_gabor.reshape((32, 32, 3)))\n",
    "    ax[1].axis('off')\n",
    "    ax[2].imshow(out2_gabor.reshape((64, 64, 3)))\n",
    "    ax[2].axis('off')\n",
    "    ax[3].imshow(out3_gabor.reshape((128, 128, 3)))\n",
    "    ax[3].axis('off')\n",
    "    ax[4].imshow(out4_gabor.reshape((256, 256, 3)))\n",
    "    ax[4].axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
